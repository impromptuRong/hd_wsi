## Create a conda environment
conda env create -n hd_env --file environment.yaml

## Run patch segmentation for sample image
python -u run_patch_inference.py --data_path assets/9388_1_1.png --model lung --output_dir ./

## Run whole slide inference with default options
CUDA_VISIBLE_DEVICES=0 python -u run_wsi_inference.py --data_path sample.svs --output_dir test_wsi

## Run WSI analysis and export segmentation mask and nuclei csv table
CUDA_VISIBLE_DEVICES=0 python -u run_wsi_inference.py --data_path sample.svs --output_dir test_wsi --save_img --save_csv

## Run whole slide inference with lung cancer model under limited computational resources
CUDA_VISIBLE_DEVICES=0 python -u run_wsi_inference.py --data_path sample.svs --model lung --output_dir test_wsi --save_img --save_csv --batch_size 4 --num_workers 8 --max_memory 1000

## Run feature extraction pipeline
CUDA_VISIBLE_DEVICES=0 python -u summarize_tme_features.py --model_res_path ./test_wsi --output_dir ./test_features --n_classes 3 --scale_factor 32 --save_images --save_nuclei

## Start a realtime server by default
ln -s /path/to/slides slides_folder
python app.py

## Start a debug server with uvicorn
uvicorn app:app --host 0.0.0.0 --port 5001 --workers 32 --log-level debug --reload

## Start a realtime server with docker
docker pull imprompturong/hd_wsi:latest
# Or build from scratch
docker build -t hd_wsi:latest .
# Run docker
docker run -p 5000:5000 -v `readlink -f /path/to/slides_folder`:/usr/src/hd_wsi/slides_folder imprompturong/hd_wsi:latest

