## Create a conda environment
conda env create --prefix /path/to/conda/env/ -f z.ml_env2_1.10.1.yaml

## Run patch segmentation for sample image
python -u run_patch_inference.py --data_path assets/9388_1_1.png --model lung --output_dir ./

## Run whole slide inference with default options
CUDA_VISIBLE_DEVICES=0 python -u run_wsi_inference.py --data_path sample.svs --output_dir test_wsi

## Generate results in folder sample_wsi
CUDA_VISIBLE_DEVICES=0 python -u run_wsi_inference.py --data_path sample.svs --output_dir test_wsi --save_img --save_csv

## Run whole slide inference for lung cancer
CUDA_VISIBLE_DEVICES=0 python -u run_wsi_inference.py --data_path 11170.svs --model lung --output_dir 11170_results --save_img

## Generate results in folder sample_tme
CUDA_VISIBLE_DEVICES=0 python -u summarize_tme_features.py --model_res_path ./test_wsi --output_dir ./test_features --n_classes 3 --scale_factor 32 --save_images

## Start a server to view original slides and the results
python -u deepzoom_server.py --data_path 11170.svs --masks 11170_results/11170.tiff --port=8000

## Start a realtime inference server
CUDA_VISIBLE_DEVICES=0 python -u deepzoom_server.py --data_path 11170.svs --model lung --port=8001

## Start a realtime server with a folder of slides
CUDA_VISIBLE_DEVICES=0 python -u deepzoom_multiserver.py --data_path /path/to/slide --model lung --port=8001

